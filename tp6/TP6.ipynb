{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP6 - Procesamiento de Lenguaje Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_style(\"darkgrid\")\n",
    "import scipy\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "from collections import Counter\n",
    "sns.plt = plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Asociacion de palabras\n",
    "1.1 Levantar el corpus AP, separando cada noticia como un elemento distinto en un diccionario ( < doc_no > : < text > ).\n",
    "\n",
    "Librerias necesarias: html5lib, lxml, bs4, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP cargado.\n",
      "Resumen de los primeros 10 documentos:\n",
      "             DOCNO                                               TEXT\n",
      "0   AP881218-0003     a    year old student at a private baptist s...\n",
      "1   AP880224-0195     the bechtel group inc  offered in      to se...\n",
      "2   AP881017-0144     a gunman took a    year old woman hostage af...\n",
      "3   AP881017-0219     today is saturday  oct      the    rd day of...\n",
      "4   AP900117-0022     cupid has a new message for lovers this vale...\n",
      "5   AP880405-0167     the reagan administration is weighing whethe...\n",
      "6   AP880825-0239     more than         skins of a protected speci...\n",
      "7   AP880325-0232     there will be no organized union boost behin...\n",
      "8   AP880908-0056     here is a summary of developments in forest ...\n",
      "9   AP881105-0097     jean pierre stirbois  the no    man in the e...\n"
     ]
    }
   ],
   "source": [
    "ap_xml_data = open('data/ap.txt').read()\n",
    "\n",
    "def xml2df(xml_data):\n",
    "    root = ET.XML(xml_data, parser=etree.XMLParser(recover=True)) # element tree\n",
    "    all_records = []\n",
    "    for i, child in enumerate(root):\n",
    "        record = {}\n",
    "        for subchild in child:\n",
    "            if subchild.tag=='DOCNO':\n",
    "                record[subchild.tag] = subchild.text\n",
    "            else:\n",
    "                record[subchild.tag] = re.sub('[^a-zA-Z*]', ' ', subchild.text).lower()\n",
    "            # Aquella regex elimina todo lo que no son letras.\n",
    "            # Para aceptar numeros, puntos y guiones: [^a-zA-Z0-9-_*.]\n",
    "            all_records.append(record)\n",
    "    return pd.DataFrame(all_records).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "ap_df = xml2df(ap_xml_data)\n",
    "\n",
    "print \"AP cargado.\"\n",
    "print \"Resumen de los primeros 10 documentos:\"\n",
    "print ap_df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Calcular el tamano del vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_vocab = dict()\n",
    "for index, row in ap_df.iterrows():\n",
    "    for word in row[1].split():\n",
    "        freq_vocab[word] = freq_vocab.get(word, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El vocabulario tiene: 33841 palabras.\n"
     ]
    }
   ],
   "source": [
    "print \"El vocabulario tiene: \" + str(len(freq_vocab)) + \" palabras.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Para las 500 palabras con mas apariciones, calcular el par mas asociado segun la medida presentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtuvieron las 500 palabras con mas apariciones.\n"
     ]
    }
   ],
   "source": [
    "max_freq_vocab = dict(sorted(freq_vocab.iteritems(), key=operator.itemgetter(1), reverse=True)[:500])\n",
    "print \"Se obtuvieron las \" + str(len(max_freq_vocab)) + \" palabras con mas apariciones.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sean X,Y palabras, N la cantidad de palabras de todos los textos, W la ventana de co-ocurrencia:\n",
    "\n",
    "f(X)=occurs(X). f(X,Y)=occurs(Y despues de X, a distancia <= W)/(W-1).\n",
    "\n",
    "P(X)=f(X)/N. P(X,Y)=f(X,Y)/N.\n",
    "\n",
    "I(X,Y)=log2(P(X,Y) / (P(X) x P(Y)))=log2( ( f(X,Y) x N ) / ( f(X) x f(Y) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_mutual_association(txts, relevant_words, W):\n",
    "    N=0\n",
    "    mutual_assoc = dict()\n",
    "    for txt in txts:\n",
    "        words = txt.split()\n",
    "        N = N + len(words)\n",
    "        for i in range(len(words)-W):\n",
    "            word = words[i]\n",
    "            if word in relevant_words:\n",
    "                for j in range(1,W):\n",
    "                    other = words[i+j]\n",
    "                    mutual_assoc[word] = mutual_assoc.get(word, dict())\n",
    "                    mutual_assoc[word][other] = mutual_assoc[word].get(other, 0) + 1\n",
    "    for word, freqs in mutual_assoc.iteritems():\n",
    "        for other, freq in freqs.iteritems():\n",
    "            fxy = float(freq / (W-1))\n",
    "            fx = float(freq_vocab[word])\n",
    "            fy = float(freq_vocab[other])\n",
    "            if fxy > 0:\n",
    "                mutual_assoc[word][other] = math.log((fxy*N)/(fx*fy),2)\n",
    "            else:\n",
    "                mutual_assoc[word][other] = 0\n",
    "    return mutual_assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mutual_assoc = calculate_mutual_association(ap_df.iloc[:,1], max_freq_vocab.keys(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo: 10 palabras mas asociadas a \"whose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 5.3744053437100066),\n",
       " ('includes', 5.050866198916659),\n",
       " ('body', 4.708474001469581),\n",
       " ('parents', 4.668396562094245),\n",
       " ('son', 4.47451682850021),\n",
       " ('include', 4.164734163474938),\n",
       " ('included', 4.110028271384802),\n",
       " ('district', 3.734099809145075),\n",
       " ('members', 3.7110161960320336),\n",
       " ('found', 3.047649486233116)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(mutual_assoc[\"whose\"].iteritems(), key=operator.itemgetter(1), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta: las palabras mas asociadas a cada una de las 500 que mas aparecen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(all,sudden)\n",
      "(dollar,midmorning)\n",
      "(month,extension)\n",
      "(four,networks)\n",
      "(go,beyond)\n",
      "(children,adults)\n",
      "(issues,outnumbered)\n",
      "(whose,name)\n",
      "(thursday,zurich)\n",
      "(to,microcom)\n",
      "(program,vremya)\n",
      "(th,anniversary)\n",
      "(under,auspices)\n",
      "(must,submit)\n",
      "(street,gainers)\n",
      "(outside,womb)\n",
      "(far,reaching)\n",
      "(every,palestinian)\n",
      "(condition,anonymity)\n",
      "(school,dances)\n",
      "(did,elaborate)\n",
      "(companies,considered)\n",
      "(wednesday,night)\n",
      "(small,caliber)\n",
      "(says,leonard)\n",
      "(leaders,issued)\n",
      "(past,decade)\n",
      "(talks,brussels)\n",
      "(rate,mortgages)\n",
      "(cost,taxpayers)\n",
      "(n,y)\n",
      "(even,though)\n",
      "(index,arbitrage)\n",
      "(what,happening)\n",
      "(business,machines)\n",
      "(near,border)\n",
      "(spokesman,gennady)\n",
      "(capital,gains)\n",
      "(new,jersey)\n",
      "(order,until)\n",
      "(public,defender)\n",
      "(told,reporters)\n",
      "(friday,night)\n",
      "(led,multinational)\n",
      "(exchange,index)\n",
      "(men,women)\n",
      "(here,excerpts)\n",
      "(hours,minutes)\n",
      "(reported,editions)\n",
      "(groups,including)\n",
      "(vice,president)\n",
      "(iraq,invaded)\n",
      "(change,mind)\n",
      "(employees,buy)\n",
      "(reports,aoun)\n",
      "(trial,gesell)\n",
      "(action,committees)\n",
      "(military,commanders)\n",
      "(ago,food)\n",
      "(family,courts)\n",
      "(reagan,administration)\n",
      "(private,consultants)\n",
      "(county,sheriff)\n",
      "(total,output)\n",
      "(market,watchers)\n",
      "(use,condoms)\n",
      "(from,lire)\n",
      "(troops,stationed)\n",
      "(would,prefer)\n",
      "(army,faction)\n",
      "(hospital,recovering)\n",
      "(two,thirds)\n",
      "(next,kin)\n",
      "(few,thousand)\n",
      "(taken,custody)\n",
      "(until,midnight)\n",
      "(today,birthdays)\n",
      "(more,than)\n",
      "(israel,egypt)\n",
      "(share,points)\n",
      "(company,quarterly)\n",
      "(known,wars)\n",
      "(women,minorities)\n",
      "(me,i)\n",
      "(high,profile)\n",
      "(rights,abuses)\n",
      "(this,morning)\n",
      "(work,performed)\n",
      "(london,bid)\n",
      "(can,afford)\n",
      "(ms,viett)\n",
      "(my,impression)\n",
      "(control,negotiators)\n",
      "(president,hoyo)\n",
      "(council,churches)\n",
      "(give,notice)\n",
      "(tax,liability)\n",
      "(states,tariffs)\n",
      "(want,die)\n",
      "(information,returns)\n",
      "(united,emirates)\n",
      "(end,apartheid)\n",
      "(six,felony)\n",
      "(how,react)\n",
      "(sunday,editions)\n",
      "(stock,exchange)\n",
      "(plans,sell)\n",
      "(may,bushel)\n",
      "(earlier,hong)\n",
      "(southern,baptist)\n",
      "(water,quality)\n",
      "(court,upheld)\n",
      "(law,establishes)\n",
      "(man,shot)\n",
      "(a,fugitive)\n",
      "(third,reich)\n",
      "(chief,rehnquist)\n",
      "(so,far)\n",
      "(africa,namibia)\n",
      "(democratic,nominee)\n",
      "(make,sure)\n",
      "(bush,kaifu)\n",
      "(help,solve)\n",
      "(office,supervision)\n",
      "(over,counter)\n",
      "(years,probation)\n",
      "(held,accountable)\n",
      "(through,canal)\n",
      "(committee,sasser)\n",
      "(japan,ltd)\n",
      "(still,holding)\n",
      "(its,tender)\n",
      "(before,dawn)\n",
      "(police,detective)\n",
      "(labor,camps)\n",
      "(late,zurich)\n",
      "(policy,glasnost)\n",
      "(weeks,ago)\n",
      "(might,follow)\n",
      "(texas,intermediate)\n",
      "(then,sharply)\n",
      "(them,away)\n",
      "(good,fortune)\n",
      "(food,shelter)\n",
      "(nation,est)\n",
      "(they,mad)\n",
      "(half,dozen)\n",
      "(not,tolerated)\n",
      "(now,defunct)\n",
      "(killed,wounded)\n",
      "(bank,gaza)\n",
      "(james,iii)\n",
      "(university,lecturer)\n",
      "(didn,realize)\n",
      "(each,individual)\n",
      "(found,guilty)\n",
      "(went,smoothly)\n",
      "(economy,maintain)\n",
      "(republican,nominee)\n",
      "(financial,institutions)\n",
      "(house,commons)\n",
      "(oil,rig)\n",
      "(trading,losers)\n",
      "(year,old)\n",
      "(our,ability)\n",
      "(saturday,night)\n",
      "(out,window)\n",
      "(jackson,vanik)\n",
      "(won,championship)\n",
      "(robert,bork)\n",
      "(since,invaded)\n",
      "(increase,magnitude)\n",
      "(re,mad)\n",
      "(investigation,meese)\n",
      "(health,hazard)\n",
      "(got,inches)\n",
      "(issue,billboard)\n",
      "(announced,candidacy)\n",
      "(after,pleading)\n",
      "(million,shiites)\n",
      "(given,chance)\n",
      "(free,lance)\n",
      "(california,berkeley)\n",
      "(york,mercantile)\n",
      "(members,delegation)\n",
      "(put,forth)\n",
      "(service,pumps)\n",
      "(could,sink)\n",
      "(days,notice)\n",
      "(times,index)\n",
      "(american,telegraph)\n",
      "(place,where)\n",
      "(think,reasonable)\n",
      "(south,africans)\n",
      "(first,republicbank)\n",
      "(major,currencies)\n",
      "(already,begun)\n",
      "(dukakis,bentsen)\n",
      "(number,tenfold)\n",
      "(one,tenfold)\n",
      "(another,speaking)\n",
      "(such,projects)\n",
      "(vote,confidence)\n",
      "(force,base)\n",
      "(george,deukmejian)\n",
      "(city,councilman)\n",
      "(little,bit)\n",
      "(district,kimba)\n",
      "(top,priorities)\n",
      "(system,segregation)\n",
      "(least,acres)\n",
      "(their,counterparts)\n",
      "(attack,came)\n",
      "(rates,midmorning)\n",
      "(too,beautiful)\n",
      "(statement,denying)\n",
      "(which,regulates)\n",
      "(white,marlin)\n",
      "(john,mccain)\n",
      "(that,compares)\n",
      "(took,pains)\n",
      "(released,recognizance)\n",
      "(part,settlement)\n",
      "(july,bushel)\n",
      "(than,doubled)\n",
      "(television,vremya)\n",
      "(second,quarter)\n",
      "(nations,sanctions)\n",
      "(charges,conspiracy)\n",
      "(defense,yazov)\n",
      "(were,undecided)\n",
      "(and,gilligan)\n",
      "(san,diego)\n",
      "(say,why)\n",
      "(have,strained)\n",
      "(sen,strom)\n",
      "(any,wrongdoing)\n",
      "(gorbachev,glasnost)\n",
      "(agency,adn)\n",
      "(also,criticized)\n",
      "(take,steps)\n",
      "(forces,militia)\n",
      "(added,however)\n",
      "(price,gouging)\n",
      "(who,spoke)\n",
      "(most,currencies)\n",
      "(eight,hours)\n",
      "(plan,calling)\n",
      "(services,committee)\n",
      "(america,pageant)\n",
      "(don,t)\n",
      "(average,industrials)\n",
      "(later,london)\n",
      "(m,edt)\n",
      "(mrs,bloomberg)\n",
      "(points,outnumbered)\n",
      "(came,shares)\n",
      "(saying,wanted)\n",
      "(show,disaster)\n",
      "(german,helmut)\n",
      "(agreed,principle)\n",
      "(based,giant)\n",
      "(state,phyllis)\n",
      "(should,contribute)\n",
      "(only,thing)\n",
      "(going,happen)\n",
      "(black,townships)\n",
      "(communist,party)\n",
      "(local,governments)\n",
      "(do,something)\n",
      "(his,fingers)\n",
      "(get,rid)\n",
      "(nearly,double)\n",
      "(reporters,aboard)\n",
      "(report,monitored)\n",
      "(during,reign)\n",
      "(trade,carla)\n",
      "(him,tell)\n",
      "(prime,menachem)\n",
      "(iran,affair)\n",
      "(countries,diplomatic)\n",
      "(eastern,europe)\n",
      "(morning,thunderstorms)\n",
      "(miles,colombo)\n",
      "(she,assaulted)\n",
      "(including,trades)\n",
      "(where,ends)\n",
      "(secretary,javier)\n",
      "(set,aside)\n",
      "(national,aeronautics)\n",
      "(see,reason)\n",
      "(officials,acknowledge)\n",
      "(are,discriminated)\n",
      "(close,ally)\n",
      "(said,baula)\n",
      "(federal,reserve)\n",
      "(away,from)\n",
      "(enough,money)\n",
      "(r,kan)\n",
      "(between,koreas)\n",
      "(across,border)\n",
      "(europe,liberty)\n",
      "(we,weep)\n",
      "(never,intended)\n",
      "(however,doesn)\n",
      "(job,discrimination)\n",
      "(cut,off)\n",
      "(opposition,lukanov)\n",
      "(group,claimed)\n",
      "(come,here)\n",
      "(both,sides)\n",
      "(last,temptation)\n",
      "(country,music)\n",
      "(according,affidavit)\n",
      "(drug,traffickers)\n",
      "(foreign,gennady)\n",
      "(april,pound)\n",
      "(s,kimba)\n",
      "(asked,approve)\n",
      "(among,refined)\n",
      "(co,upjohn)\n",
      "(point,intermediate)\n",
      "(tuesday,night)\n",
      "(others,wounded)\n",
      "(community,college)\n",
      "(anti,semitism)\n",
      "(news,conference)\n",
      "(conference,leaders)\n",
      "(union,carbide)\n",
      "(west,helmut)\n",
      "(political,spectrum)\n",
      "(three,fourths)\n",
      "(been,strained)\n",
      "(much,better)\n",
      "(interest,rates)\n",
      "(expected,approve)\n",
      "(meeting,roh)\n",
      "(board,directors)\n",
      "(life,imprisonment)\n",
      "(received,reinforcement)\n",
      "(fire,acres)\n",
      "(minister,menachem)\n",
      "(prices,tumbled)\n",
      "(an,updated)\n",
      "(former,evangelist)\n",
      "(those,exchanges)\n",
      "(case,vs)\n",
      "(east,germans)\n",
      "(these,guys)\n",
      "(bill,cosby)\n",
      "(budget,deficits)\n",
      "(air,conditioning)\n",
      "(will,tolerated)\n",
      "(while,disagreed)\n",
      "(many,economists)\n",
      "(newspaper,pravda)\n",
      "(aid,recipients)\n",
      "(seven,months)\n",
      "(ve,got)\n",
      "(cents,feeder)\n",
      "(is,element)\n",
      "(it,ironic)\n",
      "(against,currencies)\n",
      "(in,lyon)\n",
      "(if,fails)\n",
      "(pay,raises)\n",
      "(began,night)\n",
      "(administration,insistence)\n",
      "(same,telecharge)\n",
      "(member,team)\n",
      "(largest,shareholder)\n",
      "(party,monopoly)\n",
      "(several,hundred)\n",
      "(higher,elevations)\n",
      "(week,billboard)\n",
      "(used,transport)\n",
      "(director,milstead)\n",
      "(recent,weeks)\n",
      "(lower,lakes)\n",
      "(off,debts)\n",
      "(center,theater)\n",
      "(i,am)\n",
      "(well,wishers)\n",
      "(without,elaborating)\n",
      "(very,tragic)\n",
      "(the,carcass)\n",
      "(soviet,mikhail)\n",
      "(left,leg)\n",
      "(just,beginning)\n",
      "(less,than)\n",
      "(being,marketed)\n",
      "(money,laundering)\n",
      "(judge,kimba)\n",
      "(human,beings)\n",
      "(death,penalty)\n",
      "(campaign,swing)\n",
      "(rose,mofford)\n",
      "(workers,expires)\n",
      "(had,risen)\n",
      "(day,auction)\n",
      "(presidential,candidate)\n",
      "(prison,inmate)\n",
      "(has,waned)\n",
      "(chairman,yasser)\n",
      "(march,bushel)\n",
      "(around,clock)\n",
      "(government,ryzhkov)\n",
      "(big,totaled)\n",
      "(early,stages)\n",
      "(five,astronauts)\n",
      "(know,why)\n",
      "(press,marlin)\n",
      "(world,cup)\n",
      "(like,see)\n",
      "(d,alene)\n",
      "(lost,contact)\n",
      "(t,afford)\n",
      "(night,knowing)\n",
      "(security,clearances)\n",
      "(attorney,edwin)\n",
      "(because,circumstances)\n",
      "(old,fashioned)\n",
      "(people,injuring)\n",
      "(senate,judiciary)\n",
      "(some,indications)\n",
      "(back,forth)\n",
      "(economic,indicators)\n",
      "(election,cycle)\n",
      "(home,videos)\n",
      "(monday,night)\n",
      "(for,ams)\n",
      "(decision,abortion)\n",
      "(when,ambushed)\n",
      "(leader,lech)\n",
      "(be,arraigned)\n",
      "(run,media)\n",
      "(power,outage)\n",
      "(june,deadline)\n",
      "(agreement,tariffs)\n",
      "(corp,ltd)\n",
      "(although,cited)\n",
      "(by,noontime)\n",
      "(on,behalf)\n",
      "(about,miles)\n",
      "(central,bankers)\n",
      "(of,kin)\n",
      "(industry,analysts)\n",
      "(months,ago)\n",
      "(germany,nato)\n",
      "(or,indirect)\n",
      "(own,recognizance)\n",
      "(into,orbit)\n",
      "(washington,c)\n",
      "(down,unchanged)\n",
      "(right,wing)\n",
      "(her,husband)\n",
      "(area,southern)\n",
      "(support,contras)\n",
      "(there,indications)\n",
      "(long,distance)\n",
      "(way,race)\n",
      "(was,gunnison)\n",
      "(war,ii)\n",
      "(building,permits)\n",
      "(head,injuries)\n",
      "(north,koreans)\n",
      "(offer,worth)\n",
      "(but,none)\n",
      "(with,abstentions)\n",
      "(he,thrilled)\n",
      "(made,arrests)\n",
      "(whether,accept)\n",
      "(official,tass)\n",
      "(up,nasdaq)\n",
      "(us,us)\n",
      "(record,keeping)\n",
      "(called,witnesses)\n",
      "(sales,excise)\n",
      "(general,dynamics)\n",
      "(as,telecharge)\n",
      "(at,least)\n",
      "(inc,macmillan)\n",
      "(no,whatsoever)\n",
      "(peace,prize)\n",
      "(percent,humanities)\n",
      "(other,infections)\n",
      "(department,boucher)\n",
      "(you,re)\n",
      "(congress,deputies)\n",
      "(students,faculty)\n",
      "(problems,among)\n",
      "(fell,sharply)\n",
      "(authorities,investigating)\n",
      "(died,causes)\n",
      "(billion,bushels)\n",
      "(wife,kitty)\n",
      "(u,kimba)\n",
      "(time,expect)\n",
      "(international,machines)\n",
      "(rep,dellums)\n"
     ]
    }
   ],
   "source": [
    "for word, freqs in mutual_assoc.items():\n",
    "    print \"(\" + word + \",\" + str(max(freqs.iteritems(), key=operator.itemgetter(1))[0]) + \")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 -  Informacion Lexica\n",
    "Bajar de Project Gutenberg el libro de Darwin ON THE ORIGIN OF SPECIES.\n",
    "\n",
    "2.1 Procesar el texto, tokenizando eliminando signos de puntuacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Siguiendo el artıculo de la seccion, calcular la autocorrelacion para estimar la distribucion de la palabra a lo largo del texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Armar una funcion que reciba una lista de tokens, una lista de palabras y un tamano de ventana y devuelva una lista de probabilidades de encontrar la palabra en cada ventana para cada palabra pasada por parametro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Calcular la entropıa de la distribucion de palabras seleccionadas para distintos tamanos de ventana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Generar una version randomizada del texto, y medir la entropia de las palabras randomizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 Distinguir las palabras del texto en artıculos, sustantivos y adjetivos usando un POS-tagger. Verificar si las medidas separan a estos grupos de palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Word embeddings, distancia semantica y Word- Net\n",
    "3.1 Utilizando el test WordSim3531, comparar el rendimiento entre LSA[3] y Word2Vec2 [4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Comparar los distintos word embeddings con las medidas definidas en WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2",
   "language": "python",
   "name": "py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
