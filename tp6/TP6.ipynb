{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP6 - Procesamiento de Lenguaje Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_style(\"darkgrid\")\n",
    "import scipy\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "from collections import Counter\n",
    "sns.plt = plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Asociacion de palabras\n",
    "1.1 Levantar el corpus AP, separando cada noticia como un elemento distinto en un diccionario ( < doc_no > : < text > ).\n",
    "\n",
    "Librerias necesarias: html5lib, lxml, bs4, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP cargado.\n",
      "Resumen de los primeros 10 documentos:\n",
      "             DOCNO                                               TEXT\n",
      "0   AP881218-0003     A    year old student at a private Baptist s...\n",
      "1   AP880224-0195     The Bechtel Group Inc  offered in      to se...\n",
      "2   AP881017-0144     A gunman took a    year old woman hostage af...\n",
      "3   AP881017-0219     Today is Saturday  Oct      the    rd day of...\n",
      "4   AP900117-0022     Cupid has a new message for lovers this Vale...\n",
      "5   AP880405-0167     The Reagan administration is weighing whethe...\n",
      "6   AP880825-0239     More than         skins of a protected speci...\n",
      "7   AP880325-0232     There will be no organized union boost behin...\n",
      "8   AP880908-0056     Here is a summary of developments in forest ...\n",
      "9   AP881105-0097     Jean Pierre Stirbois  the No    man in the e...\n"
     ]
    }
   ],
   "source": [
    "ap_xml_data = open('data/ap.txt').read()\n",
    "\n",
    "def xml2df(xml_data):\n",
    "    root = ET.XML(xml_data, parser=etree.XMLParser(recover=True)) # element tree\n",
    "    all_records = []\n",
    "    for i, child in enumerate(root):\n",
    "        record = {}\n",
    "        for subchild in child:\n",
    "            if subchild.tag=='DOCNO':\n",
    "                record[subchild.tag] = subchild.text\n",
    "            else:\n",
    "                record[subchild.tag] = re.sub('[^a-zA-Z*]', ' ', subchild.text) \n",
    "            # Aquella regex elimina todo lo que no son letras.\n",
    "            # Para aceptar numeros, puntos y guiones: [^a-zA-Z0-9-_*.]\n",
    "            all_records.append(record)\n",
    "    return pd.DataFrame(all_records).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "ap_df = xml2df(ap_xml_data)\n",
    "\n",
    "print \"AP cargado.\"\n",
    "print \"Resumen de los primeros 10 documentos:\"\n",
    "print ap_df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Calcular el tamano del vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_vocab = dict()\n",
    "for index, row in ap_df.iterrows():\n",
    "    for word in row[1].split():\n",
    "        freq_vocab[word] = freq_vocab.get(word, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El vocabulario tiene: 38520 palabras.\n"
     ]
    }
   ],
   "source": [
    "print \"El vocabulario tiene: \" + str(len(freq_vocab)) + \" palabras.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Para las 500 palabras con mas apariciones, calcular el par mas asociado segun la medida presentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtuvieron las 500 palabras con mas apariciones.\n"
     ]
    }
   ],
   "source": [
    "max_freq_vocab = dict(sorted(freq_vocab.iteritems(), key=operator.itemgetter(1), reverse=True)[:500])\n",
    "print \"Se obtuvieron las \" + str(len(max_freq_vocab)) + \" palabras con mas apariciones.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sean X,Y palabras, N la cantidad de palabras de todos los textos, W la ventana de co-ocurrencia:\n",
    "\n",
    "f(X)=occurs(X). f(X,Y)=occurs(Y despues de X, a distancia <= W)/(W-1).\n",
    "\n",
    "P(X)=f(X)/N. P(X,Y)=f(X,Y)/N.\n",
    "\n",
    "I(X,Y)=log2(P(X,Y) / (P(X) x P(Y)))=log2( ( f(X,Y) x N ) / ( f(X) x f(Y) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_mutual_association(txts, relevant_words, W):\n",
    "    N=0\n",
    "    mutual_assoc = dict()\n",
    "    for txt in txts:\n",
    "        words = txt.split()\n",
    "        N = N + len(words)\n",
    "        for i in range(len(words)-W):\n",
    "            word = words[i]\n",
    "            if word in relevant_words:\n",
    "                for j in range(1,W):\n",
    "                    other = words[i+j]\n",
    "                    mutual_assoc[word] = mutual_assoc.get(word, dict())\n",
    "                    mutual_assoc[word][other] = mutual_assoc[word].get(other, 0.0) + 1.0\n",
    "    for word, freqs in mutual_assoc.iteritems():\n",
    "        for other, freq in freqs.iteritems():\n",
    "            fxy = freq / (W-1)\n",
    "            fx = freq_vocab[word]\n",
    "            fy = freq_vocab[other]\n",
    "            if fxy > 0:\n",
    "                mutual_assoc[word][other] = math.log((fxy*N)/(fx*fy),2)\n",
    "            else:\n",
    "                mutual_assoc[word][other] = 0\n",
    "    return mutual_assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mutual_assoc = calculate_mutual_association(ap_df.iloc[:,1], max_freq_vocab.keys(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(all,tantalizing)\n",
      "(dollar,depreciated)\n",
      "(month,enjoined)\n",
      "(four,Troiullot)\n",
      "(go,immature)\n",
      "(Communist,holdover)\n",
      "(children,alcoholics)\n",
      "(issues,Labronislav)\n",
      "(whose,Mk)\n",
      "(to,meld)\n",
      "(program,Documentation)\n",
      "(th,Breanne)\n",
      "(under,Basins)\n",
      "(must,sturdier)\n",
      "(case,costliest)\n",
      "(far,flung)\n",
      "(condition,Tieman)\n",
      "(service,Bikle)\n",
      "(school,buddy)\n",
      "(did,backflips)\n",
      "(companies,Borden)\n",
      "(German,Juden)\n",
      "(small,bordered)\n",
      "(George,Peppard)\n",
      "(says,Blitz)\n",
      "(leaders,restates)\n",
      "(Rep,Fernand)\n",
      "(past,Irrigation)\n",
      "(Department,Standards)\n",
      "(State,Shearn)\n",
      "(cost,Cremation)\n",
      "(air,brooch)\n",
      "(even,Moses)\n",
      "(index,propriatary)\n",
      "(what,Abduleh)\n",
      "(power,blackouts)\n",
      "(while,Bookstore)\n",
      "(spokesman,Satterfield)\n",
      "(capital,Courtroom)\n",
      "(new,Trivedi)\n",
      "(America,Rafko)\n",
      "(public,penetrating)\n",
      "(told,Minot)\n",
      "(led,Shizuka)\n",
      "(men,Hosli)\n",
      "(here,Hinojosa)\n",
      "(hours,Ange)\n",
      "(reported,Sunland)\n",
      "(Ms,Implementation)\n",
      "(vice,Leber)\n",
      "(change,notwithstanding)\n",
      "(Tuesday,Perus)\n",
      "(reports,measurable)\n",
      "(trial,litigators)\n",
      "(action,Proposals)\n",
      "(military,forcefully)\n",
      "(family,mull)\n",
      "(Robert,Felise)\n",
      "(When,ADAPTED)\n",
      "(private,enroll)\n",
      "(market,slippesd)\n",
      "(Europe,Bemporad)\n",
      "(use,Clerics)\n",
      "(from,influenza)\n",
      "(troops,shaving)\n",
      "(would,plenary)\n",
      "(June,Allows)\n",
      "(two,mutinied)\n",
      "(next,Czar)\n",
      "(few,Lowe)\n",
      "(Corp,NHK)\n",
      "(taken,Sealy)\n",
      "(until,Wanda)\n",
      "(today,Tondo)\n",
      "(more,talkative)\n",
      "(share,Felise)\n",
      "(company,debtholders)\n",
      "(Wednesday,retracting)\n",
      "(American,epitomized)\n",
      "(talks,recapturing)\n",
      "(known,abayas)\n",
      "(women,Chiburdanidze)\n",
      "(me,goodies)\n",
      "(high,buddy)\n",
      "(rights,concered)\n",
      "(this,centuryn)\n",
      "(work,collating)\n",
      "(can,Malian)\n",
      "(my,airfare)\n",
      "(could,inducement)\n",
      "(Inc,Pawtucket)\n",
      "(control,Contracting)\n",
      "(Police,Tieman)\n",
      "(give,Sabbath)\n",
      "(tax,Hon)\n",
      "(states,Truckee)\n",
      "(want,antagonize)\n",
      "(Party,restates)\n",
      "(information,Sanjib)\n",
      "(end,Residential)\n",
      "(six,Grandpa)\n",
      "(how,Yalobusha)\n",
      "(economy,Criticizing)\n",
      "(A,postmortem)\n",
      "(may,fabricated)\n",
      "(earlier,unhurt)\n",
      "(Mrs,Hedrick)\n",
      "(water,saturating)\n",
      "(such,Bovril)\n",
      "(law,Wednedsay)\n",
      "(man,pooled)\n",
      "(a,bronzed)\n",
      "(One,Butana)\n",
      "(chief,neonatology)\n",
      "(so,misstates)\n",
      "(make,melt)\n",
      "(help,spiralng)\n",
      "(office,Stress)\n",
      "(over,manhandled)\n",
      "(years,Presence)\n",
      "(held,Morrocan)\n",
      "(through,pigsties)\n",
      "(committee,airfare)\n",
      "(White,illustrates)\n",
      "(still,jingling)\n",
      "(its,periodicals)\n",
      "(Texas,Homochitto)\n",
      "(before,bedrock)\n",
      "(police,scooped)\n",
      "(late,Taxpayers)\n",
      "(policy,NABE)\n",
      "(weeks,dichotomy)\n",
      "(might,furloughed)\n",
      "(then,Cannibal)\n",
      "(them,flashy)\n",
      "(good,Toby)\n",
      "(food,Poisoning)\n",
      "(nation,regulars)\n",
      "(She,joie)\n",
      "(they,mutinied)\n",
      "(party,liars)\n",
      "(not,collaborate)\n",
      "(now,Zigal)\n",
      "(killed,Stompei)\n",
      "(presidential,Commanding)\n",
      "(San,golfer)\n",
      "(didn,passively)\n",
      "(each,fireplace)\n",
      "(found,attic)\n",
      "(went,Bankrolled)\n",
      "(stock,meandered)\n",
      "(oil,Yanbu)\n",
      "(trading,Disclosure)\n",
      "(year,Stompei)\n",
      "(our,Smaha)\n",
      "(out,fissures)\n",
      "(since,tycoon)\n",
      "(increase,disount)\n",
      "(re,spectaculars)\n",
      "(got,Dinsmores)\n",
      "(issue,Harper)\n",
      "(announced,reacquire)\n",
      "(after,Democatic)\n",
      "(state,Zhirinovski)\n",
      "(This,ONLY)\n",
      "(University,Danbury)\n",
      "(million,Pilgrim)\n",
      "(given,cantaloupes)\n",
      "(free,fouling)\n",
      "(members,wreath)\n",
      "(put,seals)\n",
      "(Iran,skirmishes)\n",
      "(Monday,Wisuskeow)\n",
      "(National,Multiparty)\n",
      "(days,tethered)\n",
      "(place,onus)\n",
      "(think,behoove)\n",
      "(first,Sputnik)\n",
      "(major,Grocery)\n",
      "(already,dismantlement)\n",
      "(There,Suzanne)\n",
      "(number,employeed)\n",
      "(one,Zealander)\n",
      "(another,vet)\n",
      "(president,Astrauskas)\n",
      "(vote,Emerging)\n",
      "(force,waterproof)\n",
      "(city,Lara)\n",
      "(little,necesary)\n",
      "(North,Bottoms)\n",
      "(Congress,Sentiment)\n",
      "(top,illustrators)\n",
      "(system,curtails)\n",
      "(least,exasperation)\n",
      "(their,boyhood)\n",
      "(attack,Moana)\n",
      "(rates,understate)\n",
      "(too,Edde)\n",
      "(statement,assailed)\n",
      "(Iraq,diagrammed)\n",
      "(Gorbachev,Avram)\n",
      "(that,propane)\n",
      "(took,misprinted)\n",
      "(D,Alpena)\n",
      "(released,tomorrrow)\n",
      "(part,EOG)\n",
      "(Democratic,Commanding)\n",
      "(than,spies)\n",
      "(television,speeded)\n",
      "(rate,reminiscent)\n",
      "(charges,Gib)\n",
      "(officials,salmonellosis)\n",
      "(were,helter)\n",
      "(Sen,recapturing)\n",
      "(and,Schwerner)\n",
      "(Court,Rider)\n",
      "(say,void)\n",
      "(have,invariable)\n",
      "(any,hotheads)\n",
      "(East,stocked)\n",
      "(agency,Partially)\n",
      "(also,resurrected)\n",
      "(Germany,Zolan)\n",
      "(take,invent)\n",
      "(which,depreciated)\n",
      "(added,Allegis)\n",
      "(price,cookware)\n",
      "(who,onus)\n",
      "(most,beloved)\n",
      "(eight,celebratin)\n",
      "(plan,Pesticide)\n",
      "(The,Adventures)\n",
      "(don,ts)\n",
      "(Dukakis,quipped)\n",
      "(average,rake)\n",
      "(later,Iwao)\n",
      "(Some,abolishing)\n",
      "(order,decipher)\n",
      "(R,McClure)\n",
      "(If,procrastinate)\n",
      "(Saturday,denounces)\n",
      "(came,embued)\n",
      "(saying,denouncement)\n",
      "(show,flowered)\n",
      "(Union,Resellers)\n",
      "(agreed,hath)\n",
      "(We,foursquare)\n",
      "(based,Holliston)\n",
      "(outside,Step)\n",
      "(should,razed)\n",
      "(only,premeditated)\n",
      "(going,Wth)\n",
      "(black,abayas)\n",
      "(York,Cuatro)\n",
      "(do,embarked)\n",
      "(his,nourished)\n",
      "(get,brownie)\n",
      "(reporters,Minot)\n",
      "(report,tolerates)\n",
      "(during,Refusal)\n",
      "(trade,Holmer)\n",
      "(Soviet,Nationalities)\n",
      "(him,Skolnik)\n",
      "(countries,Jian)\n",
      "(Washington,postmarked)\n",
      "(miles,Bookstore)\n",
      "(she,stares)\n",
      "(forces,bombarded)\n",
      "(including,fertilizers)\n",
      "(where,nourished)\n",
      "(set,swapping)\n",
      "(Jackson,blistering)\n",
      "(job,Desperate)\n",
      "(national,Asahi)\n",
      "(see,discontinuity)\n",
      "(defense,Tailored)\n",
      "(are,rashes)\n",
      "(close,Reef)\n",
      "(John,Betso)\n",
      "(points,NAB)\n",
      "(said,satchel)\n",
      "(That,Feeling)\n",
      "(federal,Brasilia)\n",
      "(away,vestiges)\n",
      "(enough,Wajda)\n",
      "(won,Thimble)\n",
      "(between,Miachel)\n",
      "(July,catheterization)\n",
      "(Republican,Boulter)\n",
      "(across,lowland)\n",
      "(we,Unable)\n",
      "(never,ceases)\n",
      "(court,Threw)\n",
      "(S,Aswal)\n",
      "(cut,undernourished)\n",
      "(opposition,Nacionalista)\n",
      "(group,paratroop)\n",
      "(come,Hinojosa)\n",
      "(both,wilting)\n",
      "(last,LaPorte)\n",
      "(country,barons)\n",
      "(according,prophets)\n",
      "(drug,barons)\n",
      "(foreign,winemakers)\n",
      "(s,Champagne)\n",
      "(asked,Nervous)\n",
      "(among,Lone)\n",
      "(groups,onus)\n",
      "(point,Lunenberg)\n",
      "(others,Amanda)\n",
      "(anti,Lourdes)\n",
      "(news,recouping)\n",
      "(conference,Scheduled)\n",
      "(second,Brigitte)\n",
      "(union,Adamjee)\n",
      "(political,commissar)\n",
      "(three,Bolivians)\n",
      "(But,overdo)\n",
      "(much,Sander)\n",
      "(California,farmworkers)\n",
      "(interest,Caltex)\n",
      "(expected,Faced)\n",
      "(meeting,Choosing)\n",
      "(life,Bottomley)\n",
      "(received,Elisha)\n",
      "(fire,fireballs)\n",
      "(N,Bunning)\n",
      "(prices,Allegis)\n",
      "(an,osprey)\n",
      "(former,juxtaposition)\n",
      "(those,outcomes)\n",
      "(And,Rich)\n",
      "(Co,Upjohn)\n",
      "(these,perverted)\n",
      "(bill,solver)\n",
      "(Reagan,hostess)\n",
      "(budget,Investing)\n",
      "(General,Accopunting)\n",
      "(will,Refering)\n",
      "(near,Yanbu)\n",
      "(many,overdoes)\n",
      "(newspaper,Repubblica)\n",
      "(aid,pragmatism)\n",
      "(employees,clearings)\n",
      "(City,Bancorporation)\n",
      "(seven,identifiction)\n",
      "(ve,Feeling)\n",
      "(cents,hundredweight)\n",
      "(is,unprincipled)\n",
      "(it,repertory)\n",
      "(Bush,shelve)\n",
      "(against,Gib)\n",
      "(in,indentificaton)\n",
      "(if,XYZ)\n",
      "(Israel,Sledge)\n",
      "(pay,angiography)\n",
      "(began,trickling)\n",
      "(administration,permissiveness)\n",
      "(same,Decreased)\n",
      "(member,Edmonton)\n",
      "(largest,teases)\n",
      "(President,Hosni)\n",
      "(several,courthouses)\n",
      "(higher,bloodbath)\n",
      "(week,Residential)\n",
      "(used,Designed)\n",
      "(I,Feel)\n",
      "(director,Uralmash)\n",
      "(recent,Packaging)\n",
      "(lower,extremities)\n",
      "(off,Christich)\n",
      "(Senate,abundance)\n",
      "(well,bankrolled)\n",
      "(It,raining)\n",
      "(States,Interviewing)\n",
      "(without,Morehouse)\n",
      "(In,pooled)\n",
      "(very,Edvin)\n",
      "(the,intelligentsia)\n",
      "(left,notifying)\n",
      "(United,Kingdom)\n",
      "(just,saturating)\n",
      "(less,ornamentation)\n",
      "(being,Camayagua)\n",
      "(money,upkeep)\n",
      "(half,grays)\n",
      "(Sunday,wilting)\n",
      "(death,Zvi)\n",
      "(campaign,Torrent)\n",
      "(rose,Hecla)\n",
      "(workers,Tektronix)\n",
      "(Friday,Material)\n",
      "(had,idyllic)\n",
      "(day,Wanda)\n",
      "(board,Pagan)\n",
      "(prison,Saffle)\n",
      "(has,Bigots)\n",
      "(Minister,Mieczyslaw)\n",
      "(scheduled,hangings)\n",
      "(On,Rockland)\n",
      "(around,exuberant)\n",
      "(government,tolerates)\n",
      "(James,McClure)\n",
      "(Air,Combat)\n",
      "(early,KwaThema)\n",
      "(five,Cecila)\n",
      "(know,Unable)\n",
      "(judge,Communication)\n",
      "(world,endures)\n",
      "(like,raffia)\n",
      "(London,Waterloo)\n",
      "(t,conjecture)\n",
      "(night,adorning)\n",
      "(security,ramming)\n",
      "(attorney,Margulis)\n",
      "(because,malfunctioned)\n",
      "(old,Gertrud)\n",
      "(people,blisters)\n",
      "(West,Pepperell)\n",
      "(some,extrapolates)\n",
      "(back,Unable)\n",
      "(economic,plodding)\n",
      "(election,Wycliffe)\n",
      "(New,Jersey)\n",
      "(for,immature)\n",
      "(decision,Currier)\n",
      "(when,phoned)\n",
      "(leader,Meany)\n",
      "(He,satchel)\n",
      "(be,confetti)\n",
      "(run,Damages)\n",
      "(business,Ange)\n",
      "(agreement,RTC)\n",
      "(chairman,Leber)\n",
      "(by,tsetse)\n",
      "(on,railing)\n",
      "(about,Shank)\n",
      "(of,Latter)\n",
      "(industry,Spahn)\n",
      "(months,backlogged)\n",
      "(Committee,Multiparty)\n",
      "(Japan,Hitachi)\n",
      "(or,blithely)\n",
      "(own,Vax)\n",
      "(No,responsibilty)\n",
      "(into,adorning)\n",
      "(down,meadows)\n",
      "(right,Outgoing)\n",
      "(been,Bigots)\n",
      "(her,discoverer)\n",
      "(area,brownouts)\n",
      "(support,Cilluffo)\n",
      "(there,discernible)\n",
      "(long,spencers)\n",
      "(died,Natalia)\n",
      "(way,rascals)\n",
      "(was,Westphalia)\n",
      "(war,Sunrise)\n",
      "(ago,breadth)\n",
      "(head,Worker)\n",
      "(offer,versatility)\n",
      "(but,naturalists)\n",
      "(with,shaving)\n",
      "(he,misspoken)\n",
      "(made,retch)\n",
      "(whether,salmonellosis)\n",
      "(House,illustrates)\n",
      "(official,Robeson)\n",
      "(Africa,relinquishing)\n",
      "(up,methane)\n",
      "(us,Semyonovsky)\n",
      "(record,Bonnard)\n",
      "(They,replication)\n",
      "(called,Annals)\n",
      "(m,weekdays)\n",
      "(sales,skew)\n",
      "(Thursday,Strikers)\n",
      "(general,Tierney)\n",
      "(as,nested)\n",
      "(at,stockyard)\n",
      "(home,Faine)\n",
      "(no,respiration)\n",
      "(May,Demonstrations)\n",
      "(percent,Draft)\n",
      "(other,Cordes)\n",
      "(you,Theresa)\n",
      "(students,effigy)\n",
      "(problems,Furnishes)\n",
      "(March,drowing)\n",
      "(April,lambasting)\n",
      "(fell,Scribner)\n",
      "(U,Gregorie)\n",
      "(authorities,impacts)\n",
      "(South,relinquishing)\n",
      "(billion,ceases)\n",
      "(wife,Gertrud)\n",
      "(An,snared)\n",
      "(As,harridan)\n",
      "(At,dinnertime)\n",
      "(time,Elegance)\n"
     ]
    }
   ],
   "source": [
    "for word, freqs in mutual_assoc.items():\n",
    "    print \"(\" + word + \",\" + str(max(freqs.iteritems(), key=operator.itemgetter(1))[0]) + \")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 -  Informacion Lexica\n",
    "Bajar de Project Gutenberg el libro de Darwin ON THE ORIGIN OF SPECIES.\n",
    "\n",
    "2.1 Procesar el texto, tokenizando eliminando signos de puntuacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Siguiendo el artıculo de la seccion, calcular la autocorrelacion para estimar la distribucion de la palabra a lo largo del texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Armar una funcion que reciba una lista de tokens, una lista de palabras y un tamano de ventana y devuelva una lista de probabilidades de encontrar la palabra en cada ventana para cada palabra pasada por parametro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Calcular la entropıa de la distribucion de palabras seleccionadas para distintos tamanos de ventana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Generar una version randomizada del texto, y medir la entropia de las palabras randomizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 Distinguir las palabras del texto en artıculos, sustantivos y adjetivos usando un POS-tagger. Verificar si las medidas separan a estos grupos de palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Word embeddings, distancia semantica y Word- Net\n",
    "3.1 Utilizando el test WordSim3531, comparar el rendimiento entre LSA[3] y Word2Vec2 [4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Comparar los distintos word embeddings con las medidas definidas en WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2",
   "language": "python",
   "name": "py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
